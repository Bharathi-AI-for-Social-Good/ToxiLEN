{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f89d8ffe",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import numpy as np\n",
    "from dataset.cindy_dataset import MemeDataset\n",
    "from config import config\n",
    "from models.main_model import MemeMultimodalDetector\n",
    "\n",
    "from scripts.trainer.trainer import quick_smoke_train\n",
    "from scripts.trainer.model_factory import build_model\n",
    "\n",
    "from utils.logger import get_logger"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "34c10766",
   "metadata": {},
   "outputs": [],
   "source": [
    "logger = get_logger()\n",
    "\n",
    "variants = [\"shared_encoder\"]\n",
    "seeds    = [42, 43]\n",
    "cfg      = {\"batch_size\": 8, \"device\": \"cuda\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "02a00947",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = MemeDataset(config['train'])\n",
    "val_dataset = MemeDataset(config['test'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88b3c93b",
   "metadata": {},
   "source": [
    "##### Smoke Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2008ad83",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n",
      "d:\\pandalow_playgrounds\\project\\Toxilen_model\\scripts\\trainer\\trainer.py:89: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
      "[EP 1/3]:   0%|          | 0/3 [00:00<?, ?it/s]d:\\pandalow_playgrounds\\project\\Toxilen_model\\scripts\\trainer\\trainer.py:97: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "[EP 1/3]: 100%|██████████| 3/3 [00:11<00:00,  3.67s/it]\n",
      "VAL: 100%|██████████| 3/3 [00:09<00:00,  3.11s/it]\n",
      "C:\\Users\\zxj00\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\zxj00\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\zxj00\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP1  loss=0.123  macroF1=0.4138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EP 2/3]:   0%|          | 0/3 [00:00<?, ?it/s]d:\\pandalow_playgrounds\\project\\Toxilen_model\\scripts\\trainer\\trainer.py:97: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
      "[EP 2/3]: 100%|██████████| 3/3 [00:09<00:00,  3.31s/it]\n",
      "VAL: 100%|██████████| 3/3 [00:09<00:00,  3.11s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP2  loss=0.060  macroF1=0.4711\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EP 3/3]:   0%|          | 0/3 [00:00<?, ?it/s]d:\\pandalow_playgrounds\\project\\Toxilen_model\\scripts\\trainer\\trainer.py:97: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
      "[EP 3/3]: 100%|██████████| 3/3 [00:09<00:00,  3.18s/it]\n",
      "VAL: 100%|██████████| 3/3 [00:09<00:00,  3.05s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP3  loss=0.030  macroF1=0.5096\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pandalow_playgrounds\\project\\Toxilen_model\\scripts\\trainer\\trainer.py:89: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
      "[EP 1/3]:   0%|          | 0/3 [00:00<?, ?it/s]d:\\pandalow_playgrounds\\project\\Toxilen_model\\scripts\\trainer\\trainer.py:97: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "[EP 1/3]: 100%|██████████| 3/3 [00:09<00:00,  3.15s/it]\n",
      "VAL: 100%|██████████| 3/3 [00:08<00:00,  2.94s/it]\n",
      "C:\\Users\\zxj00\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\zxj00\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\zxj00\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP1  loss=0.133  macroF1=0.4138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EP 2/3]:   0%|          | 0/3 [00:00<?, ?it/s]d:\\pandalow_playgrounds\\project\\Toxilen_model\\scripts\\trainer\\trainer.py:97: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
      "[EP 2/3]: 100%|██████████| 3/3 [00:09<00:00,  3.18s/it]\n",
      "VAL: 100%|██████████| 3/3 [00:09<00:00,  3.14s/it]\n",
      "C:\\Users\\zxj00\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\zxj00\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
      "C:\\Users\\zxj00\\AppData\\Roaming\\Python\\Python312\\site-packages\\sklearn\\metrics\\_classification.py:1531: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP2  loss=0.063  macroF1=0.4138\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EP 3/3]:   0%|          | 0/3 [00:00<?, ?it/s]d:\\pandalow_playgrounds\\project\\Toxilen_model\\scripts\\trainer\\trainer.py:97: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
      "[EP 3/3]: 100%|██████████| 3/3 [00:09<00:00,  3.28s/it]\n",
      "VAL: 100%|██████████| 3/3 [00:09<00:00,  3.00s/it]\n",
      "2025-07-18 21:47:32,256 [INFO] [Mini] shared_encoder: 46.17 ± 4.79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP3  loss=0.035  macroF1=0.3929\n"
     ]
    }
   ],
   "source": [
    "mini_results = {}\n",
    "for name in variants:\n",
    "    f1_list = []\n",
    "    for sd in seeds:\n",
    "        model = build_model(name)\n",
    "        best_f1,_,_,_ = quick_smoke_train(\n",
    "            model, cfg,\n",
    "            train_dataset, val_dataset,\n",
    "            train_frac=0.02,  # 2 % train\n",
    "            val_frac=0.05,    # 5 % test\n",
    "            epochs=3,\n",
    "            seed=sd,\n",
    "            lr=5e-5\n",
    "        )\n",
    "        f1_list.append(best_f1)\n",
    "    mini_results[name] = (np.mean(f1_list), np.std(f1_list))\n",
    "    logger.info(f\"[Mini] {name}: {mini_results[name][0]*100:.2f} ± {mini_results[name][1]*100:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07bd9f84",
   "metadata": {},
   "source": [
    "##### Mini ablation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a036d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "mini_results = {}\n",
    "for name in variants:\n",
    "    f1_list = []\n",
    "    for sd in seeds:\n",
    "        model = build_model(name)\n",
    "        best_f1, _ , model , _= quick_smoke_train(\n",
    "            model, cfg,\n",
    "            train_dataset, val_dataset,\n",
    "            train_frac=0.10,  # 10 % 训练\n",
    "            val_frac=0.30,    # 30 % 验证\n",
    "            epochs=10,\n",
    "            seed=sd,\n",
    "            lr=1e-5\n",
    "        )\n",
    "        f1_list.append(best_f1)\n",
    "    mini_results[name] = (np.mean(f1_list), np.std(f1_list))\n",
    "    print(f\"[Mini] {name}: {mini_results[name][0]*100:.2f} ± {mini_results[name][1]*100:.2f}\")\n",
    "    print(model.bi_gate.last_score1)\n",
    "    print(model.bi_gate.last_score2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c8ffd82",
   "metadata": {},
   "source": [
    "##### Full Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8e782b71",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\pandalow_playgrounds\\project\\Toxilen_model\\scripts\\trainer\\trainer.py:89: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  scaler = torch.cuda.amp.GradScaler(enabled=use_amp)\n",
      "[EP 1/15]:   0%|          | 0/149 [00:00<?, ?it/s]d:\\pandalow_playgrounds\\project\\Toxilen_model\\scripts\\trainer\\trainer.py:97: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
      "Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "[EP 1/15]: 100%|██████████| 149/149 [02:05<00:00,  1.19it/s]\n",
      "VAL: 100%|██████████| 43/43 [00:23<00:00,  1.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP1  loss=3.369  macroF1=0.9079\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EP 2/15]:   0%|          | 0/149 [00:00<?, ?it/s]d:\\pandalow_playgrounds\\project\\Toxilen_model\\scripts\\trainer\\trainer.py:97: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
      "[EP 2/15]: 100%|██████████| 149/149 [01:48<00:00,  1.38it/s]\n",
      "VAL: 100%|██████████| 43/43 [00:18<00:00,  2.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP2  loss=0.714  macroF1=0.9230\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EP 3/15]:   0%|          | 0/149 [00:00<?, ?it/s]d:\\pandalow_playgrounds\\project\\Toxilen_model\\scripts\\trainer\\trainer.py:97: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
      "[EP 3/15]: 100%|██████████| 149/149 [01:45<00:00,  1.41it/s]\n",
      "VAL: 100%|██████████| 43/43 [00:21<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP3  loss=0.172  macroF1=0.9363\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EP 4/15]:   0%|          | 0/149 [00:00<?, ?it/s]d:\\pandalow_playgrounds\\project\\Toxilen_model\\scripts\\trainer\\trainer.py:97: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
      "[EP 4/15]: 100%|██████████| 149/149 [01:37<00:00,  1.52it/s]\n",
      "VAL: 100%|██████████| 43/43 [00:21<00:00,  1.97it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP4  loss=0.163  macroF1=0.9238\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EP 5/15]:   0%|          | 0/149 [00:00<?, ?it/s]d:\\pandalow_playgrounds\\project\\Toxilen_model\\scripts\\trainer\\trainer.py:97: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
      "[EP 5/15]: 100%|██████████| 149/149 [01:33<00:00,  1.59it/s]\n",
      "VAL: 100%|██████████| 43/43 [00:27<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP5  loss=0.124  macroF1=0.8878\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EP 6/15]:   0%|          | 0/149 [00:00<?, ?it/s]d:\\pandalow_playgrounds\\project\\Toxilen_model\\scripts\\trainer\\trainer.py:97: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
      "[EP 6/15]: 100%|██████████| 149/149 [01:36<00:00,  1.54it/s]\n",
      "VAL: 100%|██████████| 43/43 [00:26<00:00,  1.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP6  loss=0.048  macroF1=0.9155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EP 7/15]:   0%|          | 0/149 [00:00<?, ?it/s]d:\\pandalow_playgrounds\\project\\Toxilen_model\\scripts\\trainer\\trainer.py:97: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
      "[EP 7/15]: 100%|██████████| 149/149 [01:36<00:00,  1.54it/s]\n",
      "VAL: 100%|██████████| 43/43 [00:23<00:00,  1.82it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP7  loss=0.006  macroF1=0.9155\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EP 8/15]:   0%|          | 0/149 [00:00<?, ?it/s]d:\\pandalow_playgrounds\\project\\Toxilen_model\\scripts\\trainer\\trainer.py:97: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
      "[EP 8/15]: 100%|██████████| 149/149 [01:38<00:00,  1.51it/s]\n",
      "VAL: 100%|██████████| 43/43 [00:23<00:00,  1.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP8  loss=0.003  macroF1=0.9221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EP 9/15]:   0%|          | 0/149 [00:00<?, ?it/s]d:\\pandalow_playgrounds\\project\\Toxilen_model\\scripts\\trainer\\trainer.py:97: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
      "[EP 9/15]: 100%|██████████| 149/149 [01:37<00:00,  1.52it/s]\n",
      "VAL: 100%|██████████| 43/43 [00:22<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP9  loss=0.002  macroF1=0.9221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EP 10/15]:   0%|          | 0/149 [00:00<?, ?it/s]d:\\pandalow_playgrounds\\project\\Toxilen_model\\scripts\\trainer\\trainer.py:97: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
      "[EP 10/15]: 100%|██████████| 149/149 [01:38<00:00,  1.52it/s]\n",
      "VAL: 100%|██████████| 43/43 [00:27<00:00,  1.57it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP10  loss=0.001  macroF1=0.9221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EP 11/15]:   0%|          | 0/149 [00:00<?, ?it/s]d:\\pandalow_playgrounds\\project\\Toxilen_model\\scripts\\trainer\\trainer.py:97: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
      "[EP 11/15]: 100%|██████████| 149/149 [01:38<00:00,  1.52it/s]\n",
      "VAL: 100%|██████████| 43/43 [00:22<00:00,  1.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP11  loss=0.001  macroF1=0.9221\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EP 12/15]:   0%|          | 0/149 [00:00<?, ?it/s]d:\\pandalow_playgrounds\\project\\Toxilen_model\\scripts\\trainer\\trainer.py:97: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
      "[EP 12/15]: 100%|██████████| 149/149 [01:36<00:00,  1.54it/s]\n",
      "VAL: 100%|██████████| 43/43 [00:22<00:00,  1.87it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP12  loss=0.001  macroF1=0.9188\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[EP 13/15]:   0%|          | 0/149 [00:00<?, ?it/s]d:\\pandalow_playgrounds\\project\\Toxilen_model\\scripts\\trainer\\trainer.py:97: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast(enabled=use_amp):\n",
      "[EP 13/15]: 100%|██████████| 149/149 [01:45<00:00,  1.42it/s]\n",
      "VAL: 100%|██████████| 43/43 [00:22<00:00,  1.92it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EP13  loss=0.001  macroF1=0.9155\n",
      "Early stopping triggered\n",
      "★ Final Macro F1: 0.93625\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "best_variant = \"shared_encoder\"\n",
    "final_model  = build_model(best_variant)\n",
    "\n",
    "best_f1, report, model, val_loader = quick_smoke_train(\n",
    "    final_model, cfg,\n",
    "    train_dataset, val_dataset,\n",
    "    train_frac=1.0,\n",
    "    val_frac=1.0,\n",
    "    epochs=15,\n",
    "    seed=42,\n",
    "    lr=1e-5,\n",
    "    early_stop_patience=10\n",
    ")\n",
    "print(\"★ Final Macro F1:\", best_f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2b37f4b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The new embeddings will be initialized from a multivariate normal distribution that has old embeddings' mean and covariance. As described in this article: https://nlp.stanford.edu/~johnhew/vocab-expansion.html. To disable this, use `mean_resizing=False`\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = build_model(\"shared_encoder\")\n",
    "model.load_state_dict(torch.load(\"checkpoint-model-temp.pth\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9cb4c08d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test:   0%|          | 0/43 [00:00<?, ?it/s]Asking to truncate to max_length but no maximum length is provided and the model has no predefined maximum length. Default to no truncation.\n",
      "Test: 100%|██████████| 43/43 [00:07<00:00,  5.38it/s]\n",
      "2025-07-18 22:53:26,008 [INFO]               precision    recall  f1-score   support\n",
      "\n",
      "           0     0.9549    0.9873    0.9708       236\n",
      "           1     0.9688    0.8942    0.9300       104\n",
      "\n",
      "    accuracy                         0.9588       340\n",
      "   macro avg     0.9618    0.9408    0.9504       340\n",
      "weighted avg     0.9591    0.9588    0.9583       340\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "([0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0],\n",
       " [0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  0,\n",
       "  0,\n",
       "  0,\n",
       "  1,\n",
       "  1,\n",
       "  0])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from scripts.trainer.predict import test\n",
    "test(model, config['test'],val_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7db7449a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
